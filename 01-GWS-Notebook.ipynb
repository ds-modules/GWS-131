{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "import ipywidgets as widgets\n",
    "from scipy import stats\n",
    "%matplotlib inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to GWS-131's Data Science Module!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Python and Jupyter Notebooks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cells - Text and Code\n",
    "In a notebook, each rectangle containing text or code is called a *cell*.\n",
    "\n",
    "Cells (like this one) can be edited by double-clicking on them. This cell is a text cell, written in a simple format called [Markdown](http://daringfireball.net/projects/markdown/syntax) to add formatting and section headings.  You don't need to worry about Markdown today, but it's a pretty fun+easy tool to learn.\n",
    "\n",
    "After you edit a cell, click the \"run cell\" button at the top that looks like â–¶| to confirm any changes. (Try not to delete the instructions.) You can also press `SHIFT-ENTER` to run any cell or progress from one cell to the next.\n",
    "\n",
    "Other cells contain code in the Python3 programming language.  Running a code cell will execute all of the code it contains.\n",
    "\n",
    "Try running this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello, World!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Numbers\n",
    "\n",
    "Quantitative information arises everywhere in data science. In addition to representing commands to print out lines, expressions can represent numbers and methods of combining numbers. The expression `3.2500` evaluates to the number 3.25. (Run the cell and see.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3.2500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(3)\n",
    "4\n",
    "5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we don't necessarily need to `print`. When you run a notebook cell, if the last line has a value, then Jupyter helpfully prints out that value for you. However, it won't print out prior lines automatically. If you wish to print out multiple lines, then the `print` function is helpful!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Arithmetic\n",
    "Many basic arithmetic operations are built in to Python.  The Data 8 textbook section on [Expressions](http://www.inferentialthinking.com/chapters/03/1/expressions.html) describes all the arithmetic operators used in the course.  The common operator that differs from typical math notation is `**`, which raises one number to the power of the other. So, `2**3` stands for $2^3$ and evaluates to 8. \n",
    "\n",
    "The order of operations is what you learned in elementary school, and Python also has parentheses.  For example, compare the outputs of the cells below. Use parentheses for a happy new year!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "1+(6*5-(6*3))**2*((2**3)/4*7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Names\n",
    "In natural language, we have terminology that lets us quickly reference very complicated concepts.  We don't say, \"That's a large mammal with brown fur and sharp teeth!\"  Instead, we just say, \"Bear!\"\n",
    "\n",
    "Similarly, an effective strategy for writing code is to define names for data as we compute it, like a lawyer would define terms for complex ideas at the start of a legal document.\n",
    "\n",
    "In Python, we do this with *assignment statements*. An assignment statement has a name on the left side of an `=` sign and an expression to be evaluated on the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty = (3 * 11 + 5) / 2 - 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you run that cell, Python first evaluates the expression on the right: it computes the value of the expression `(3 * 11 + 5) / 2 - 9 `, which is the number 10.  Then it assigns that value the name `twenty`.  At that point, the code in the cell is done running.\n",
    "\n",
    "After you run that cell, the value 10 is bound to the name `twenty`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Functions\n",
    "\n",
    "    \n",
    "One important form of an expression is the call expression, which first names a function and then describes its arguments. The function returns some value, based on its arguments. Some important mathematical functions are\n",
    "\n",
    "| Function | Description                                                   |\n",
    "|----------|---------------------------------------------------------------|\n",
    "| `abs`      | Returns the absolute value of its argument                    |\n",
    "| `max`      | Returns the maximum of all its arguments                      |\n",
    "| `min`      | Returns the minimum of all its arguments                      |\n",
    "| `pow`      | Raises its first argument to the power of its second argument |\n",
    "| `round`    | Round its argument to the nearest integer                     |\n",
    "\n",
    "Here are two call expressions that both evaluate to 3\n",
    "\n",
    "    abs(2 - 5)\n",
    "    max(round(2.8), min(pow(2, 10), -1 * pow(2, 10)))\n",
    "\n",
    "All these expressions are **compound expressions**, meaning that they are actually combinations of several smaller expressions.  `2 + 3` combines the expressions `2` and `3` by addition.  In this case, `2` and `3` are called **subexpressions** because they're expressions that are part of a larger expression.\n",
    "\n",
    "A **statement** is a whole line of code.  Some statements are just expressions, like the examples above, that can be broken down into its subexpressions which get evaluated individually before evaluating the statement as a whole.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Calling functions\n",
    "\n",
    "The most common way to combine or manipulate values in Python is by calling functions. Python comes with many built-in functions that perform common operations.\n",
    "\n",
    "For example, the `abs` function takes a single number as its argument and returns the absolute value of that number.  The absolute value of a number is its distance from 0 on the number line, so `abs(5)` is 5 and `abs(-5)` is also 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions can be called as above, putting the argument in parentheses at the end, or by using \"dot notation\", and calling the function after finding the arguments, as in the cell immediately below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = make_array(1,2,5) # a list of numbers, will be explained in more detail soon\n",
    "nums.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Strings\n",
    "\n",
    "A `string` is a type of data, usually composed of alphabetical characters. A string is always enclosed in single or double quotations.\n",
    "\n",
    "You can create variables that hold strings, and you can create strings to be any sequence of letters, numbers, and special characters that you want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"I'm a string!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's nothing stopping a string from being a number, but you can't do normal numerical operations on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"I'm a string\"\n",
    "sentence*4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are, however, some convenient functions that allow you to convert strings to numbers, and numbers to strings: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero = '0'\n",
    "int(zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Strings as function arguments**\n",
    "\n",
    "String values, like numbers, can be arguments to functions and can be returned by functions.  The function `len` takes a single string as its argument and returns the number of characters in the string: its **len**-gth.  \n",
    "\n",
    "Note that it doesn't count *words*. \n",
    "\n",
    "**Challenge**\n",
    "\n",
    "Use `len` to find out the number of characters in the string `welcome` below:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "welcome = \"Welcome to this class!\"\n",
    "\n",
    "# your code below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Importing code\n",
    "\n",
    "\n",
    "Most programming involves work that is very similar to work that has been done before.  Since writing code is time-consuming, it's good to rely on others' published code when you can.  Rather than copy-pasting, Python allows us to **import** other code, creating a **module** that contains all of the names created by that code.\n",
    "\n",
    "Python includes many useful modules that are just an `import` away.  We'll look at the `math` module as a first example. The `math` module is extremely useful in computing mathematical expressions in Python. \n",
    "\n",
    "Suppose we want to very accurately compute the area of a circle with radius 5 meters.  For that, we need the constant $\\pi$, which is roughly 3.14.  Conveniently, the `math` module has `pi` defined for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "radius = 5\n",
    "area_of_circle = radius**2 * math.pi\n",
    "area_of_circle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pi` is defined inside `math`, and the way that we access names that are inside modules is by writing the module's name, then a dot, then the name of the thing we want:\n",
    "\n",
    "    <module name>.<name>\n",
    "    \n",
    "In order to use a module at all, we must first write the statement `import <module name>`.  That statement creates a module object with things like `pi` in it and then assigns the name `math` to that module.  Above we have done that for `math`. If you wish to use a module in more than one cell, however, you only need to import it once â€” the first time you want to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating factorials.\n",
    "math.factorial(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating square roots.\n",
    "math.sqrt(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Arrays\n",
    "\n",
    "Up to now, we haven't done much that you couldn't do yourself by hand, without going through the trouble of learning Python.  Computers are most useful when you can use a small amount of code to *do the same action* to *many things at once*.\n",
    "\n",
    "\n",
    "**Arrays** are how we put many values in one place so that we can operate on them as a group. For example, if `billions_of_numbers` is an array of numbers, the expression\n",
    "\n",
    "```python\n",
    ".10 * billions_of_numbers\n",
    "```\n",
    "\n",
    "gives a new array of numbers that's the result of multiplying each number in `billions_of_numbers` by .10 (10%).  Arrays are not limited to numbers; we can also put all the words in a book into an array of strings.\n",
    "\n",
    "Concretely, an array is a **collection of values of the same type**, like a column in an Excel spreadsheet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1. Making arrays\n",
    "You can type in the data that goes in an array yourself, but that's not typically how programs work. Normally, we create arrays by loading them from an external source, like a data file.\n",
    "\n",
    "First, though, let's learn how to do it the hard way. Execute the following cell so that all the names from the `datascience` module are available to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to create an array, call the function `make_array`.  Each argument you pass to `make_array` will be in the array it returns.  Run this cell to see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_array = make_array(0.125, 4.75, -1.3)\n",
    "my_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each value in an array (in the above case, the numbers 0.125, 4.75, and -1.3) is called an *element* of that array.\n",
    "\n",
    "Arrays themselves are also values, just like numbers and strings.  That means you can assign them names or use them as arguments to functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_array.item(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we wrote .item(0), not .item(1), to get the first element. This is a weird convention in programming and computer science: indices start at 0 instead of 1. So the first thing in an array is item 0, the second is item 1, and so on. It is also described as the number of elements that appear before that item. So 3 is the index of the 4th item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Creating Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we don't have a spreadsheet file and are starting with nothing, first we need to make arrays. In the case of a table, we'll consider an array as either a row or a column. Let's make two arrays below that will become our columns, one for some of our U.S. presidents and one for the year they were born."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "president_names = make_array(\"Jefferson\", \"Garfield\", \"Eisenhower\", \"Obama\")\n",
    "president_birth = make_array(1743, 1831, 1890, 1961)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to make a table using these arrays, we use the general form:\n",
    "\n",
    "```python\n",
    "Table( ).with_columns(\"Column Name\", array_name, . . .)\n",
    "```\n",
    "\n",
    "We assign the created table to a variable (just like the arrays from above), and then type that variable name to display the table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres_table = Table().with_columns(\"President\", president_names,\n",
    "                                  \"Birth Year\", president_birth)\n",
    "pres_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `with_columns` can also be used to add additional columns to existing tables, replacing `Table()` with the name of the table you want to add columns to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres_with_pets = pres_table.with_columns(\"Pet Name\", make_array(\"Buzzy\", \"Veto\", \"Heidi\", \"Bo\"))\n",
    "pres_with_pets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Importing\n",
    "\n",
    "It's more likey that a file holding your data already exists. In general, to import data from a file, we write:\n",
    "\n",
    "```python\n",
    "Table.read_table(\"file_name\")\n",
    "```\n",
    "\n",
    "Most often, these file names end in `.csv` to show the data format. `.csv` format is popular for spreadsheets and can be imported/exported from programs such as Microsoft Excel, OpenOffice Calc, or Google spreadsheets. \n",
    " \n",
    "An example is shown below using [U.S. Census data](http://www2.census.gov/programs-surveys/popest/datasets/2010-2015/national/asrh/nc-est2015-agesex-res.csv). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data = Table.read_table(\"http://www2.census.gov/programs-surveys/popest/datasets/2010-2015/national/asrh/nc-est2015-agesex-res.csv\")\n",
    "census_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of information. As you can see from the labels on top, this table shows Biological Sex (0=total, 1=male, 2=female), Age,  2010 Census Information, and predictions for U.S. population for the next five years. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Using Tables\n",
    "\n",
    "We can make criteria to cut down tables. Accessing only the rows, columns, or values specfic to our purpose makes information easier understood. Analysis and conclusions can be made when data is more digestible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook can calculate how large this table is with two functions: `num_rows` and `num_columns`. The general form for these functions are `<table>.num_rows` and `<table>.num_columns`. \n",
    "\n",
    "Let's use these on the table above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data.num_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a 306 x 10 table! We can first start to cut down this table using only some columns. Let's only include biological sex, age and the estimated base for 2010 census data. \n",
    "\n",
    "   There are two methods to make a table with select columns included, `select` or `drop`:\n",
    "\n",
    "- `select` can create a new table with only the columns indicated in the parameters \n",
    "- `drop` can create a new table with columns NOT indicated in the parameters\n",
    "\n",
    "\n",
    "Here's an example of two equal lines: (keep in mind that we assign each new table to a new variable, to make organization easier). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_census_data = census_data.select(\"SEX\", \"AGE\", \"ESTIMATESBASE2010\")\n",
    "select_census_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_census_data = census_data.drop(\"CENSUS2010POP\",\"POPESTIMATE2010\",\"POPESTIMATE2011\",\"POPESTIMATE2012\",\"POPESTIMATE2013\",\"POPESTIMATE2014\",\"POPESTIMATE2015\")\n",
    "drop_census_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two cells above give us the same resulting table, but `select` was easier to use since we only cared about a few columns. The resulting table was still pretty large (3x306), so our next step to cut it down even more is to only include non-gendered data AKA data where SEX=0, neither male or female specific.\n",
    "\n",
    "To do this, we need to use a new function `where`. The general form of this function is:\n",
    "\n",
    "```python\n",
    "table.where(column_name, predicate)\n",
    "```\n",
    "\n",
    "To cut our table down to only include `sex=0`, we may use the predicate `are.equal_to()`. Note that we are assigning the new table to a new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_census_data = select_census_data.where(\"SEX\", are.equal_to(0))\n",
    "new_census_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still 92 rows omitted! Let's take every 10th entry to cut this table down a little more. \n",
    "\n",
    "To do this we need to use the `take` function. The `take` function creates a new table with rows from the original table whose indices (row numbers) are given. Remember, in Python, indices start at 0! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_10_year = new_census_data.take([0,10,20,30,40,50,60,70,80,90])\n",
    "census_10_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that sex is all the same, we can drop that column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_census_table = census_10_year.drop(\"SEX\")\n",
    "final_census_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Tables Essentials!\n",
    "\n",
    "For your reference, here's a table of all the useful `Table` functions we've used so far:\n",
    "\n",
    "|Name|Example|Purpose|\n",
    "|-|-|-|\n",
    "|`Table`|`Table()`|Create an empty table, usually to extend with data|\n",
    "|`Table.read_table`|`Table.read_table(\"my_data.csv\")`|Create a table from a data file|\n",
    "|`with_columns`|`tbl = Table().with_columns(\"N\", np.arange(5), \"2*N\", np.arange(0, 10, 2))`|Create a copy of a table with more columns|\n",
    "|`column`|`tbl.column(\"N\")`|Create an array containing the elements of a column|\n",
    "|`sort`|`tbl.sort(\"N\")`|Create a copy of a table sorted by the values in a column|\n",
    "|`where`|`tbl.where(\"N\", are.above(2))`|Create a copy of a table with only the rows that match some *predicate*|\n",
    "|`num_rows`|`tbl.num_rows`|Compute the number of rows in a table|\n",
    "|`num_columns`|`tbl.num_columns`|Compute the number of columns in a table|\n",
    "|`select`|`tbl.select(\"N\")`|Create a copy of a table with only some of the columns|\n",
    "|`drop`|`tbl.drop(\"2*N\")`|Create a copy of a table without some of the columns|\n",
    "|`take`|`tbl.take(np.arange(0, 6, 2))`|Create a copy of the table with only the rows whose indices are in the given array|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 Merging Tables\n",
    "\n",
    "Merging two tables allows us to consolidate information that may be spread across multiple data sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Columns\n",
    "\n",
    "We discussed this briefly in an earlier section; you can add new columns to a table by using the `with_columns` method that we learned about when creating new tables. \n",
    "\n",
    "Let's pretend that we suddenly have access to the favorite foods of each president from our earlier table. We can merge in a new column to the initial table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres_table_with_food = pres_table.with_columns(\"Favorite food\", make_array(\"Pizza\", \"Snickers\", \"Grapes\", \"Escargot\"))\n",
    "pres_table_with_food"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Rows\n",
    "\n",
    "Now let's assume we have a new president's information to add to our table, stored on its own in another table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pres = Table().with_columns(\"President\", make_array(\"Ford\"),\n",
    "                               \"Birth Year\", make_array(1913),\n",
    "                               \"Favorite food\", make_array(\"Mac & Cheese\"))\n",
    "new_pres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add our new president's information to our original table with the `append` function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pres_combined = pres_table_with_food.copy()\n",
    "new_pres_combined.append(new_pres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joining Tables on Columns\n",
    "\n",
    "Let's say we have another table with some additional information on our presidents that we'd like to combine with our original table, but the rows aren't in the same order as our original table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "places = make_array(\"Hawaii\", \"Ohio\", \"Virginia\", \"Texas\")\n",
    "new_pres_info = Table().with_columns(\"President\", [\"Obama\", \"Garfield\", \"Jefferson\", \"Eisenhower\"],\n",
    "                                      \"Birth Place\", places)\n",
    "new_pres_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a method called `join`, which combines two tables based on one column of information that they share, in this case, our column of their names (\"President\"). The syntax of a call to `join` requires 3 arguments, the column name of table1 on which you wish to join, the name of table2, and (optionally) the name of the column in table2 on which you wish to join, in the case that the name differs.\n",
    "```python\n",
    "table1.join(column1_name, table2, (column2_name))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres_table_with_food.join(\"President\", new_pres_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.4 Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a manageable table we can start making visualizations! Below is a handy chart with all of the visualization functions we'll be working with and how you call them.\n",
    "\n",
    "|Plotting type | | Call structure |\n",
    "|-|-|-|\n",
    "|Scatter | | `table.scatter(\"x column\", \"y column\")` |\n",
    "|Line | | `table.plot(\"x column\", \"y column\")` |\n",
    "|Bar | | `table.bar(\"x column\", \"y column\")` |\n",
    "|Horiz. Bar | | `table.barh(\"x column\", \"y column\")` |\n",
    "|Histogram | | `table.hist(\"x axis\", bins(optional), unit(optional))` |\n",
    "\n",
    "\n",
    "We'll quickly go through an example of each of these, so you get an idea for how the plots should look. We'll go back to our census data that we were working with before. If you don't recall, we stored our final manipulations of the census data into `final_census_table`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_census_table.scatter(\"AGE\", \"ESTIMATESBASE2010\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_census_table.plot(\"AGE\", \"ESTIMATESBASE2010\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_census_table.bar(\"AGE\", \"ESTIMATESBASE2010\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also create horizontal bar charts using the method `barh`, which creates a bar chart with the same information as `bar`, aligned horizontally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_census_table.barh(\"AGE\", \"ESTIMATESBASE2010\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last visualization technique you may use is the histogram. A histogram is a type of visualization where data is grouped into ranges; those ranges are then plotted as bars. This one is a little trickier than the ones above.\n",
    "\n",
    "Bins are contiguous intervals (that span over each of the data groupings) so a dataset may be grouped together. Bin parameters are inclusive on the left end and exclusive on the right on or math wise: `[a, b)`. \n",
    "\n",
    "Adjustments can be made on bins to include high or low outliers. We will see this using the original unmodified census data table, `census_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data.hist(\"AGE\", unit= \"year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each bar contains the percent of the population that falls into that bin. The total number of individuals in each bar corresponds to the area of a bar, which is found by multiplying the bar's height (the percent) by the bar's base (in this case, `100` per bin).\n",
    "\n",
    "This chart may appear confusing at first. What we are seeing is that the vast majority of individuals in our census data was between the ages of 0 and 100, which makes a lot of sense.  There are some outliers in the 100 to 200 age range, which is also possible, and in the 900 to 1000 age range, which is likely due to a documentation issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tables \n",
    "\n",
    "For a collection of things in the world, an array is useful for describing a single attribute of each thing. For example, among the collection of US States, an array could describe the land area of each. Tables extend this idea by describing multiple attributes for each element of a collection.\n",
    "\n",
    "In most data science applications, we have data about many entities, but we also have several kinds of data about each entity.\n",
    "\n",
    "When we import data later in this lab, it will import into a table format.\n",
    "\n",
    "### Analyzing datasets\n",
    "With just a few table methods, we can answer some interesting questions about datasets.\n",
    "\n",
    "We can extract single columns, which are arrays themselves, and do math on them (averaging, max, min, etc), which we'll do on real data soon. We can also rearrange the order of rows in a table by the values in any column, add more rows or columns, filter tables to select only rows that meet certain criteria, and much more!\n",
    "\n",
    "### Tables Essentials!\n",
    "\n",
    "For your reference, here's a table of all the functions and methods we saw in this lab.\n",
    "\n",
    "|Name|Example|Purpose|\n",
    "|-|-|-|\n",
    "|`Table`|`Table()`|Create an empty table, usually to extend with data|\n",
    "|`Table.read_table`|`Table.read_table(\"my_data.csv\")`|Create a table from a data file|\n",
    "|`with_columns`|`tbl = Table().with_columns(\"N\", np.arange(5), \"2*N\", np.arange(0, 10, 2))`|Create a copy of a table with more columns|\n",
    "|`column`|`tbl.column(\"N\")`|Create an array containing the elements of a column|\n",
    "|`sort`|`tbl.sort(\"N\")`|Create a copy of a table sorted by the values in a column|\n",
    "|`where`|`tbl.where(\"N\", are.above(2))`|Create a copy of a table with only the rows that match some *predicate*|\n",
    "|`num_rows`|`tbl.num_rows`|Compute the number of rows in a table|\n",
    "|`num_columns`|`tbl.num_columns`|Compute the number of columns in a table|\n",
    "|`select`|`tbl.select(\"N\")`|Create a copy of a table with only some of the columns|\n",
    "|`drop`|`tbl.drop(\"2*N\")`|Create a copy of a table without some of the columns|\n",
    "|`take`|`tbl.take(np.arange(0, 6, 2))`|Create a copy of the table with only the rows whose indices are in the given array|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# UC Berkeley\n",
    "\n",
    "We're going to start right here at UCB! These data are from Fall 2015.\n",
    "\n",
    "*Source: UC Corporate Personnel System*\n",
    "\n",
    "**Note**: STEM includes engineering and computer science, life sciences, math, medicine, other health sciences and physical sciences.\n",
    "\n",
    "Let's read in a CSV file. A CSV file is a common storage device for spreadsheet data and is also easily manipulated and exported by using programs like Excel.\n",
    "\n",
    "These data will give us the ratio of female ladder rank equivalent (LRE), which are tenure and tenure track faculty at Berkeley, in the respective divisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "UCB_LRE_female = Table.read_table('data/UCB-percent-female-LRE.csv').drop(1)\n",
    "UCB_LRE_female.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quickly plot these data on a bar graph using the `barh` function, so that we can best visually compare between disciplines over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UCB_LRE_female.barh('Discipline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you notice about the proportions of female LRE faculty across disciplines? Discuss with the people around you, and write a few sentences about it below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Type your response here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "We see in other published materials that over the ten year period there has been an increase in underrepresented minorities at UCB:\n",
    "\n",
    "<img src=\"data/gender_subject.png\" alt=\"gender_subject\" style=\"width: 400px;\"/>\n",
    "\n",
    "The increase in the share of ladder-rank and equivalent (LRE) faculty who are underrepresented minorities has largely been due to an increase in the Hispanic/Latino(a) group. Representation by American Indian and African American faculty remains a challenge.\n",
    "\n",
    "Female LRE faculty have grown in share over time, fueled by increased diversity in hiring. Their proportion differs significantly depending on discipline.\n",
    "\n",
    "<img src=\"data/subject_line_graph.png\" alt=\"subject_line_graph\" style=\"width: 400px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "## UCOP Payroll Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at another dataset that has the payroll for all UC empoloyees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UCB_data = Table.read_table('data/UCOP.csv')\n",
    "UCB_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look only at professors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rd = UCB_data.select(2,3,4,5).sort(3, descending=True)\n",
    "professors = rd.where(\"Title\", are.equal_to(\"PROF-AY\"))\n",
    "professors.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Big money!\n",
    "\n",
    "We can visualize the distribution of pay with a histogram, but the histogram (counting frequencies of a specific pay level) will change depending upon the \"bin size\" of these pay levels. We can make an interactive slider to see this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_bins(bin_size=1):\n",
    "    professors.select(3).hist(bins=np.arange(0,500000,bin_size*2000))\n",
    "\n",
    "slider = widgets.IntSlider(min=1,max=10,step=1,value=5)\n",
    "display(widgets.interactive(hist_bins, bin_size=slider))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the drawbacks and advantages of different bin sizes?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salary for males vs. females on the UC payroll\n",
    "\n",
    "While we don't have gender data in this dataset, we can use a pre-trained machine learning model to predict gender based on first name (we will forget for a moment that creating binary categories of male and female is problematic to begin with). While this is ***certainly not 100% accurate***, it is more like around 80%, we can use it to get a better idea of salaries for different genders.\n",
    "\n",
    "Here is an example of what the classification model can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.gender import classify_gender\n",
    "\n",
    "classify_gender(\"Daniel\"), classify_gender(\"Katherine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add a new column to our professors table with the gender classification output by the model for each professor's name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "professors.append_column(\"Gender\", [classify_gender(name) for name in professors['First Name']])\n",
    "professors.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge**\n",
    "\n",
    "Now let's investigate the average salary amounts for female vs. male professors, try to use what you've learned so far to get the `mean` of `Gross Pay` by gender from the `professors` table, and then make a `bar` plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can we conclude from this analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "## Silicon Valley\n",
    "\n",
    "These data are compiled from EEO-1 reports from Apple, Twitter, Salesforce, Facebook, Microsoft, and Intel. The EEO-1 is a document required by the federal government that provides the raw numbers of employees in each of the categories below. We summed the most recent data (all from 2014-16) for these companies to get the table below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tech_data = Table.read_table('data/eeo-aggregate.csv')\n",
    "tech_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at a basic bar chart of all males and females by job category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_data.select(['Job Categories', 'All Male', 'All Female']).barh('Job Categories')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also break down each gender by race:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "females = [c for c in tech_data.to_df().columns if \"Female\" in c]\n",
    "tech_data.select(['Job Categories'] + females).barh('Job Categories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "males = [c for c in tech_data.to_df().columns if \"Male\" in c]\n",
    "tech_data.select(['Job Categories'] + males).barh('Job Categories')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you see in this data? (**Note**: It might be a little hard to see since the bars are so small - zoom in!)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Bay Area Census data\n",
    "\n",
    "Let's read in a CSV file with Bay Area data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bay_area = Table().read_table('data/bay_area_data.csv')\n",
    "bay_area.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job code subset\n",
    "\n",
    "As you can see above, this table has a lot of information. The variables are in the columns and each row represents an individual. First, we will subset this table to only include the occupations we want to analyze. Job codes are listed in the column `OCC2010`. We're going to focus on management and stem jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_codes = [10, 20, 30, 100, 110, 120, 130, 140, 150, 160, 220, 300, 310, 330, 350, 360, 410, 420,\n",
    "             620, 700, 710, 720, 730, 800, 820, 940, 950, 1000, 1010, 1020, 1050, 1060, 1100, 1200, 1220,\n",
    "             1230, 1240, 1350, 1360, 1400, 1410, 1420, 1430, 1450, 1460, 1540, 1550, 1720, 1910, 1920,\n",
    "             1980, 2840, 2900, 4000, 4010, 4030, 4050, 4060, 4110, 4120, 4130, 4140, 4150, 4200, 4210,\n",
    "             4220, 4230, 4250, 4720, 5000, 7720, 7730, 7900, 8000, 8010, 8030, 8060, 8800, 8830, 7700,\n",
    "             9620, 9630, 9640]\n",
    "\n",
    "df = bay_area.to_df()\n",
    "bay_area_cut = Table.from_df(df.loc[df['OCC2010'].isin(job_codes)])\n",
    "bay_area_cut.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although still large, a table with 13110 rows has now decreased to 2550 by selecting rows that match our job_codes array. Let's subset this further by picking out specific variables we want to look at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_bay_area= bay_area_cut.drop(\"CPSID\",\"ASECFLAG\",\"HWTSUPP\", \"HFLAG\", \"MONTH\", \"PERNUM\", \"CPSIDP\",\"WTSUPP\")\n",
    "cut_bay_area.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column of job codes in \"OCC2010\" still does not paint a picture of who is doing which jobs. To solve this, we may add a job sector classification. The array \"sector\" is created below by the function \"job categories\". Following the code below, if an array (such as the job code column) is ran through the job_categories function, an array of corresponding sectors is outputted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_categories = {\"STEM\": [700, 1000, 1010, 1020, 1050, 1220, 1230, 1240, 1350, 1360, 1400, 1410, 1420, 1430, 1450,1460, 1540, 1550, 1720, 1910, 1920, 1980,2840, 2900,7720, 7730, 7900, 8000, 8010,8030, 8060, 8800, 8830],\n",
    "                  \"SERVICE\": [7700, 9620, 9630, 9640, 4000, 4010, 4030, 4050, 4060, 4110, 4120, 4130, 4140, 4150, 4720],\n",
    "                  \"FINANCIAL\": [120, 800, 820, 940, 950],\n",
    "                  \"CUSTODIAL\": [4200, 4210, 4220, 4230, 4250],\n",
    "                  \"MANAGEMENT\": [130, 150, 160, 220, 30, 100, 410, 420],\n",
    "                  \"STEM_MANAGER\": [140,300,330, 350, 360, 1060, 1100],\n",
    "                  \"ADMINISTRATOR\": [10,20]}\n",
    "\n",
    "job_categories = dict((v,k) for k in job_categories for v in job_categories[k])\n",
    "\n",
    "sectors = []\n",
    "for job in cut_bay_area.column(\"OCC2010\"):\n",
    "    try:\n",
    "        sectors.append(job_categories[job])\n",
    "    except:\n",
    "        sectors.append(\"UNKNOWN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can add the sector of each individual's job into a column by using the `with_column` function as seen below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_sector = cut_bay_area.with_column('SECTOR', sectors)\n",
    "with_sector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might have noticed this earlier but race in this table is listed as a number. To make analyis more intuitive, let's change the race codes into what they mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_dict = {'White': list(range(100,200)),\n",
    "             'Black': list(range(200,300)),\n",
    "             'Indigenous': list(range(300,400)),\n",
    "             'Asian': list(range(400,500)),\n",
    "             'Pacific Islander': list(range(500,600)),\n",
    "             'Other': list(range(600,700)),\n",
    "             'NA': list(range(700,900))}\n",
    "\n",
    "race_dict = dict((v,k) for k in race_dict for v in race_dict[k])\n",
    "\n",
    "with_race = Table.from_df(with_sector.to_df().replace({\"RACE\": race_dict, \"SEX\": {1: \"MALE\", 2: \"FEMALE\"}}))\n",
    "with_race.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, \"White\" is a pretty big ethnicity group, this may be due to the fact that \"White\" encompasses a lot according to the 2010 U.S. Census. The definitions of White include Middle Easterners, North Africans and the majority of Hispanic people in the United States. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_race.to_df()['RACE'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_race.to_df().groupby(['SECTOR', 'SEX'])['SEX'].count().unstack().plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_race.to_df().groupby(['SECTOR', 'RACE'])['RACE'].count().unstack().plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in set(sectors):\n",
    "    df = with_race.to_df()\n",
    "    df[df['SECTOR'] == s].groupby(['RACE', 'SEX'])['SEX'].count().unstack().plot.bar(stacked=True, title=s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "By looking at the average mean of each part of the sample, we see some differences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Income by race and gender\n",
    "\n",
    "**Challenge**\n",
    "\n",
    "Use our table `with_race` to get `groupby` `SEX` and then get the mean of `INCTOT`, then plot this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same for `RACE`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This type of comparison isn't very reliable. We will perform a p-value test to determine if the change of income across races/ sex is statistically significant. To do this we first need to bootstrap our sample to make a 95% confidence interval of the estimated population mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_median(original_sample, label, replications):\n",
    "    '''\n",
    "    Returns an array of bootstrapped sample medians:\n",
    "    original_sample: table containing the original sample\n",
    "    label: label of column containing the variable\n",
    "    replications: number of bootstrap samples\n",
    "    '''\n",
    "    just_one_column = original_sample.select(label)\n",
    "    medians = make_array()\n",
    "    for i in np.arange(replications):\n",
    "        bootstrap_sample = just_one_column.sample()\n",
    "        resampled_median = percentile(50, bootstrap_sample.column(0))\n",
    "        medians = np.append(medians, resampled_median)\n",
    "\n",
    "    return medians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at `MALE` vs. `FEMALE`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_dict = {}\n",
    "for i, s in enumerate(['MALE', 'FEMALE']):\n",
    "    subset = Table.from_df(df[df['SEX'] == s])\n",
    "    medians= bootstrap_median(subset, \"INCTOT\", 1000)\n",
    "    median_dict[s] = medians\n",
    "    left = percentile(2.5, medians)\n",
    "    right = percentile(97.5, medians)\n",
    "    CI = make_array(left, right)\n",
    "    print(\"The median 95% Confidence Interval for \" + s + \" is\", CI)\n",
    "    plt.plot(CI, make_array(i, i), lw=10, label=s)\n",
    "plt.legend(bbox_to_anchor=(1.01, 1), loc='upper left', ncol=1)\n",
    "plt.title('Bootstrap Median Income Confidence Intervals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate the p-value from the median samples to determine whether the difference is significant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(median_dict['MALE'], median_dict['FEMALE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look by `RACE`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_dict = {}\n",
    "for i, r in enumerate(set(df['RACE'])):\n",
    "    subset = Table.from_df(df[df['RACE'] == r])\n",
    "    medians= bootstrap_median(subset, \"INCTOT\", 1000)\n",
    "    median_dict[r] = medians\n",
    "    left = percentile(2.5, medians)\n",
    "    right = percentile(97.5, medians)\n",
    "    CI = make_array(left, right)\n",
    "    print(\"The median 95% Confidence Interval for \" + r + \" is\", CI)\n",
    "    plt.plot(CI, make_array(i, i), lw=10, label=r)\n",
    "plt.legend(bbox_to_anchor=(1.01, 1), loc='upper left', ncol=1)\n",
    "plt.title('Bootstrap Median Income Confidence Intervals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do a one way F test to see if there is significance in the difference between the median samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.f_oneway(median_dict['NA'], median_dict['Other'], median_dict['Indigenous'], median_dict['White'], median_dict['Black'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a fancy tool to give us all the combinations of `SEX` and `RACE` and then get the confidence intervals for those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "combos = [i for i in itertools.product(set(df['RACE']), ['MALE', 'FEMALE'])]\n",
    "combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, c in enumerate(combos):\n",
    "    subset = df[df['RACE'] == c[0]]\n",
    "    subset = Table.from_df(subset[subset['SEX'] == c[1]])\n",
    "    medians= bootstrap_median(subset, \"INCTOT\", 1000)\n",
    "    left = percentile(2.5, medians)\n",
    "    right = percentile(97.5, medians)\n",
    "    CI = make_array(left, right)\n",
    "    print(\"The median 95% Confidence Interval for \" + c[0] + ' ' + c[1] + \" is\", CI)\n",
    "    plt.plot(CI, make_array(i, i), lw=10, label=c[0] + ' ' + c[1])\n",
    "plt.legend(bbox_to_anchor=(1.01, 1), loc='upper left', ncol=1)\n",
    "plt.title('Bootstrap Median Income Confidence Intervals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss this plot with the people around you and write a response below."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "## Compared to entire Bay Area census sample\n",
    "\n",
    "So how does our tech-biased subset compare to the entire census subset of the Bay Area? First we'll do some quick processing to get out non-responses and relabel the Bay Area subset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bay_area2 = bay_area.to_df().replace({\"RACE\": race_dict, \"SEX\": {1: \"MALE\", 2: \"FEMALE\"}})\n",
    "bay_area2 = bay_area2[bay_area2[\"INCTOT\"] != 0]\n",
    "bay_area2 = bay_area2[bay_area2[\"INCTOT\"] != 99999999]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check to see what our sample contains in terms of `SEX` and `RACE`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bay_area2['SEX'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bay_area2['SEX'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bay_area2['RACE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bay_area2['RACE'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then look at income by `SEX` and `RACE`. Let's start with `SEX`.\n",
    "\n",
    "### `SEX`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bay_area_mean_sex = bay_area2.groupby(['SEX'])['INCTOT'].mean()\n",
    "bay_area_mean_sex.plot.bar()\n",
    "bay_area_mean_sex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll recall that our biased subset had much higher means, but similar disparity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this plot is the same as the one in the previous section with job codes - copied here for your reference\n",
    "with_race_mean_sex = with_race.to_df().groupby(['SEX'])['INCTOT'].mean()\n",
    "with_race_mean_sex.plot.bar()\n",
    "with_race_mean_sex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UCB is doing much better than both of these subsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "professors_mean_sex = professors.to_df().groupby(['Gender'])['Gross Pay'].mean()\n",
    "professors_mean_sex.plot.bar()\n",
    "professors_mean_sex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can put each of these bar charts together to get a better idea of how the numbers in each of these subsets relate to each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.DataFrame([bay_area_mean_sex, with_race_mean_sex, professors_mean_sex], [\"Entire Bay Area\", \"Biased subset\", \"Professors\"])\n",
    "b.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, combining the charts in a different way to group the numbers for each gender together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2 = pd.DataFrame(list(zip(bay_area_mean_sex, with_race_mean_sex, professors_mean_sex)), bay_area_mean_sex.keys())\n",
    "ax = b2.plot.bar()\n",
    "ax.legend([\"Entire Bay Area\", \"Biased subset\", \"Professors\"], loc=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also calculate the differences between average wages of males and females in each of our population subsets. The table below is the complete table with the wages of each gender for each group, which we used in the charts above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the difference, we subtract the amount of each gender group's wages from each other, and get the numbers below. These numbers represent how much more males earn than females in each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b['MALE'] - b['FEMALE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about `FEMALE` as a percentage of `MALE`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b['FEMALE'] / b['MALE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `RACE`\n",
    "We can also look at `RACE` in the larger Bay Area subset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bay_area_mean_race = bay_area2.groupby(['RACE'])['INCTOT'].mean()\n",
    "bay_area_mean_race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bay_area_mean_race.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our biased subset was also great here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_race_mean_race = with_race.to_df().groupby(['RACE'])['INCTOT'].mean()\n",
    "with_race_mean_race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_race_mean_race.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we'll put these charts together so we can better compare how these different subsets' numbers relate to each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.DataFrame(list(zip(bay_area_mean_race, with_race_mean_race)), bay_area_mean_race.keys())\n",
    "ax = b.plot.bar(stacked=False)\n",
    "ax.legend([\"Entire Bay Area\", \"Biased subset\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we noted when we were investigating the data from workers in the Tech industry, it is more helpful to consider race and gender together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bay_area2.groupby(['RACE', 'SEX'])['INCTOT'].mean().unstack().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_race.to_df().groupby(['RACE', 'SEX'])['INCTOT'].mean().unstack().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where are the disparities the worst?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "***Please fill out our [modules feedback survey](https://goo.gl/forms/QCgq3B5uA5npe5ja2)!***"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
