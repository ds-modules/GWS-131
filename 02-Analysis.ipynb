{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "import ipywidgets as widgets\n",
    "from scipy import stats\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tables \n",
    "\n",
    "For a collection of things in the world, an array is useful for describing a single attribute of each thing. For example, among the collection of US States, an array could describe the land area of each. Tables extend this idea by describing multiple attributes for each element of a collection.\n",
    "\n",
    "In most data science applications, we have data about many entities, but we also have several kinds of data about each entity.\n",
    "\n",
    "When we import data later in this lab, it will import into a table format.\n",
    "\n",
    "### Analyzing datasets\n",
    "With just a few table methods, we can answer some interesting questions about datasets.\n",
    "\n",
    "We can extract single columns, which are arrays themselves, and do math on them (averaging, max, min, etc), which we'll do on real data soon. We can also rearrange the order of rows in a table by the values in any column, add more rows or columns, filter tables to select only rows that meet certain criteria, and much more!\n",
    "\n",
    "### Tables Essentials!\n",
    "\n",
    "For your reference, here's a table of all the functions and methods we saw in this lab.\n",
    "\n",
    "|Name|Example|Purpose|\n",
    "|-|-|-|\n",
    "|`Table`|`Table()`|Create an empty table, usually to extend with data|\n",
    "|`Table.read_table`|`Table.read_table(\"my_data.csv\")`|Create a table from a data file|\n",
    "|`with_columns`|`tbl = Table().with_columns(\"N\", np.arange(5), \"2*N\", np.arange(0, 10, 2))`|Create a copy of a table with more columns|\n",
    "|`column`|`tbl.column(\"N\")`|Create an array containing the elements of a column|\n",
    "|`sort`|`tbl.sort(\"N\")`|Create a copy of a table sorted by the values in a column|\n",
    "|`where`|`tbl.where(\"N\", are.above(2))`|Create a copy of a table with only the rows that match some *predicate*|\n",
    "|`num_rows`|`tbl.num_rows`|Compute the number of rows in a table|\n",
    "|`num_columns`|`tbl.num_columns`|Compute the number of columns in a table|\n",
    "|`select`|`tbl.select(\"N\")`|Create a copy of a table with only some of the columns|\n",
    "|`drop`|`tbl.drop(\"2*N\")`|Create a copy of a table without some of the columns|\n",
    "|`take`|`tbl.take(np.arange(0, 6, 2))`|Create a copy of the table with only the rows whose indices are in the given array|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# UC Berkeley\n",
    "\n",
    "We're going to start right here at UCB! These data are from Fall 2015.\n",
    "\n",
    "*Source: UC Corporate Personnel System*\n",
    "\n",
    "**Note**: STEM includes engineering and computer science, life sciences, math, medicine, other health sciences and physical sciences.\n",
    "\n",
    "Let's read in a CSV file. A CSV file is a common storage device for spreadsheet data and is also easily manipulated and exported by using programs like Excel.\n",
    "\n",
    "These data will give us the ratio of female ladder rank equivalent (LRE), which are tenure and tenure track faculty at Berkeley, in the respective divisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "UCB_LRE_female = Table.read_table('data/UCB-percent-female-LRE.csv').drop(1)\n",
    "UCB_LRE_female.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quickly plot these data on a bar graph, so that we can best visually compare between disciplines over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "UCB_LRE_female.barh('Discipline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you notice about the proportions of female LRE faculty across disciplines? Discuss with the people around you.\n",
    "\n",
    "---\n",
    "\n",
    "We see in other published materials that over the ten year period there has been an increase in underrepresented minorities at UCB:\n",
    "\n",
    "<img src=\"data/gender_subject.png\" alt=\"gender_subject\" style=\"width: 400px;\"/>\n",
    "\n",
    "The increase in the share of ladder-rank and equivalent (LRE) faculty who are underrepresented minorities has largely been due to an increase in the Hispanic/Latino(a) group. Representation by American Indian and African American faculty remains a challenge.\n",
    "\n",
    "Female LRE faculty have grown in share over time, fueled by increased diversity in hiring. Their proportion differs significantly depending on discipline.\n",
    "\n",
    "<img src=\"data/subject_line_graph.png\" alt=\"subject_line_graph\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "## UCOP Payroll Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at another dataset that has the payroll for all UC empoloyees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "UCB_data = Table.read_table('data/UCOP.csv')\n",
    "UCB_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look only at professors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rd = UCB_data.select(2,3,4,5).sort(3, descending=True)\n",
    "professors = rd.where(\"Title\", are.equal_to(\"PROF-AY\"))\n",
    "professors.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Big money!\n",
    "\n",
    "We can visualize the distribution of pay with a histogram, but the histogram (counting frequencies of a specific pay level) will change depending upon the \"bin size\" of these pay levels. We can make an interactive slider to see this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hist_bins(bin_size=1):\n",
    "    professors.select(3).hist(bins=np.arange(0,500000,bin_size*2000))\n",
    "\n",
    "slider = widgets.IntSlider(min=1,max=10,step=1,value=5)\n",
    "display(widgets.interactive(hist_bins, bin_size=slider))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the drawbacks and advantages of different bin sizes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Type your response here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salary for males vs. females on the UC payroll\n",
    "\n",
    "While we don't have gender data in this dataset, we can use a pre-trained machine learning model to predict gender based on first name (we will forget for a moment that creating binary categories of male and female is problematic to begin with). While this is ***certainly not 100% accurate***, it is more like around 80%, we can use it to get a better idea of salaries for different genders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scripts.gender import classify_gender\n",
    "\n",
    "classify_gender(\"Daniel\"), classify_gender(\"Katherine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "professors.append_column(\"Gender\", [classify_gender(name) for name in professors['First Name']])\n",
    "professors.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "professors.to_df().groupby(['Gender'])['Gross Pay'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "professors.to_df().groupby(['Gender'])['Gross Pay'].mean().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can we conclude from this analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "## Silicon Valley\n",
    "\n",
    "These data are compiled from EEO-1 reports from Apple, Twitter, Salesforce, Facebook, Microsoft, and Intel. The EEO-1 is a document required by the federal government that provides the raw numbers of employees in each of the categories below. We summed the most recent data (all from 2014-16) for these companies to get the table below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tech_data = Table.read_table('data/eeo-aggregate.csv')\n",
    "tech_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at a basic bar chart of all males and females by job category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tech_data.select(['Job Categories', 'All Male', 'All Female']).barh('Job Categories')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also break down each gender by race:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tech_data.select(['Job Categories'] + females).barh('Job Categories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tech_data.select(['Job Categories'] + males).barh('Job Categories')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you see in this data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Bay Area Census data\n",
    "\n",
    "Let's read in a CSV file with Bay Area data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bay_area = Table().read_table('data/bay_area_data.csv')\n",
    "bay_area.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job code subset\n",
    "\n",
    "As you can see above, this table has a lot of information. The variables are in the columns and each row is an observation. First, we will subset this table to only include the occupations we want to analyze. Job codes are listed in the column `OCC2010`. We're going to focus on management and stem jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "job_codes = [10, 20, 30, 100, 110, 120, 130, 140, 150, 160, 220, 300, 310, 330, 350, 360, 410, 420,\n",
    "             620, 700, 710, 720, 730, 800, 820, 940, 950, 1000, 1010, 1020, 1050, 1060, 1100, 1200, 1220,\n",
    "             1230, 1240, 1350, 1360, 1400, 1410, 1420, 1430, 1450, 1460, 1540, 1550, 1720, 1910, 1920,\n",
    "             1980, 2840, 2900, 4000, 4010, 4030, 4050, 4060, 4110, 4120, 4130, 4140, 4150, 4200, 4210,\n",
    "             4220, 4230, 4250, 4720, 5000, 7720, 7730, 7900, 8000, 8010, 8030, 8060, 8800, 8830, 7700,\n",
    "             9620, 9630, 9640]\n",
    "\n",
    "df = bay_area.to_df()\n",
    "bay_area_cut = Table.from_df(df.loc[df['OCC2010'].isin(job_codes)])\n",
    "bay_area_cut.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although still large, a table with 13110 rows has now decreased to 2550 by selecting rows that match our job_codes array. Let's subset this further by picking out specific variables we want to look at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cut_bay_area= bay_area_cut.drop(\"CPSID\",\"ASECFLAG\",\"HWTSUPP\", \"HFLAG\", \"MONTH\", \"PERNUM\", \"CPSIDP\",\"WTSUPP\")\n",
    "cut_bay_area.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column of job codes in \"OCC2010\" still does not paint a picture of who is doing which jobs. To solve this, we may add a job sector classification. The array \"sector\" is created below by the function \"job categories\". Following the code below, if an array (such as the job code column) is ran through the job_categories function, an array of corresponding sectors is outputted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "job_categories = {\"STEM\": [700, 1000, 1010, 1020, 1050, 1220, 1230, 1240, 1350, 1360, 1400, 1410, 1420, 1430, 1450,1460, 1540, 1550, 1720, 1910, 1920, 1980,2840, 2900,7720, 7730, 7900, 8000, 8010,8030, 8060, 8800, 8830],\n",
    "                  \"SERVICE\": [7700, 9620, 9630, 9640, 4000, 4010, 4030, 4050, 4060, 4110, 4120, 4130, 4140, 4150, 4720],\n",
    "                  \"FINANCIAL\": [120, 800, 820, 940, 950],\n",
    "                  \"CUSTODIAL\": [4200, 4210, 4220, 4230, 4250],\n",
    "                  \"MANAGEMENT\": [130, 150, 160, 220, 30, 100, 410, 420],\n",
    "                  \"STEM_MANAGER\": [140,300,330, 350, 360, 1060, 1100],\n",
    "                  \"ADMINISTRATOR\": [10,20]}\n",
    "\n",
    "job_categories = dict((v,k) for k in job_categories for v in job_categories[k])\n",
    "\n",
    "sectors = []\n",
    "for job in cut_bay_area.column(\"OCC2010\"):\n",
    "    try:\n",
    "        sectors.append(job_categories[job])\n",
    "    except:\n",
    "        sectors.append(\"UNKNOWN\")\n",
    "len(sectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can add the sector of each individual as a column by using the `with_column` function as seen below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with_sector = cut_bay_area.with_column('SECTOR', sectors)\n",
    "with_sector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might have noticed this earlier but race in this table is listed as a number. To make analyis more intuitive, let's change the race codes into what they mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "race_dict = {'White': list(range(100,200)),\n",
    "             'Black': list(range(200,300)),\n",
    "             'Indigenous': list(range(300,400)),\n",
    "             'Asian': list(range(400,500)),\n",
    "             'Pacific Islander': list(range(500,600)),\n",
    "             'Other': list(range(600,700)),\n",
    "             'NA': list(range(700,900))}\n",
    "\n",
    "race_dict = dict((v,k) for k in race_dict for v in race_dict[k])\n",
    "\n",
    "with_race = Table.from_df(with_sector.to_df().replace({\"RACE\": race_dict, \"SEX\": {1: \"MALE\", 2: \"FEMALE\"}}))\n",
    "with_race.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, \"White\" is a pretty big ethnicity group, this may be due to the fact that \"White\" encompasses a lot according to the 2010 U.S. Census. The definitions of White include Middle Easterners, North Africans and the majority of Hispanic people in the United States. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with_race.to_df()['RACE'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with_race.to_df().groupby(['SECTOR', 'SEX'])['SEX'].count().unstack().plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with_race.to_df().groupby(['SECTOR', 'RACE'])['RACE'].count().unstack().plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for s in set(sectors):\n",
    "    df = with_race.to_df()\n",
    "    df[df['SECTOR'] == s].groupby(['RACE', 'SEX'])['SEX'].count().unstack().plot.bar(stacked=True, title=s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "By looking at the average mean of each part of the sample, we see some differences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Income by race and gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with_race.to_df().groupby(['SEX'])['INCTOT'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with_race.to_df().groupby(['SEX'])['INCTOT'].mean().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with_race.to_df().groupby(['RACE'])['INCTOT'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with_race.to_df().groupby(['RACE'])['INCTOT'].mean().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This type of comparison isn't very reliable. We will perform a p-value test to determine if the change of income across races/ sex is statistically significant. To do this we first need to bootstrap our sample to make a 95% confidence interval of the estimated population mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bootstrap_median(original_sample, label, replications):\n",
    "    '''\n",
    "    Returns an array of bootstrapped sample medians:\n",
    "    original_sample: table containing the original sample\n",
    "    label: label of column containing the variable\n",
    "    replications: number of bootstrap samples\n",
    "    '''\n",
    "    just_one_column = original_sample.select(label)\n",
    "    medians = make_array()\n",
    "    for i in np.arange(replications):\n",
    "        bootstrap_sample = just_one_column.sample()\n",
    "        resampled_median = percentile(50, bootstrap_sample.column(0))\n",
    "        medians = np.append(medians, resampled_median)\n",
    "\n",
    "    return medians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at `MALE` vs. `FEMALE`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "median_dict = {}\n",
    "for i, s in enumerate(['MALE', 'FEMALE']):\n",
    "    subset = Table.from_df(df[df['SEX'] == s])\n",
    "    medians= bootstrap_median(subset, \"INCTOT\", 1000)\n",
    "    median_dict[s] = medians\n",
    "    left = percentile(2.5, medians)\n",
    "    right = percentile(97.5, medians)\n",
    "    CI = make_array(left, right)\n",
    "    print(\"The median 95% Confidence Interval for \" + s + \" is\", CI)\n",
    "    plt.plot(CI, make_array(i, i), lw=10, label=s)\n",
    "plt.legend(bbox_to_anchor=(1.01, 1), loc='upper left', ncol=1)\n",
    "plt.title('Bootstrap Median Income Confidence Intervals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate the p-value from the median samples to determine whether the difference is significant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats.ttest_ind(median_dict['MALE'], median_dict['FEMALE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look by `RACE`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "median_dict = {}\n",
    "for i, r in enumerate(set(df['RACE'])):\n",
    "    subset = Table.from_df(df[df['RACE'] == r])\n",
    "    medians= bootstrap_median(subset, \"INCTOT\", 1000)\n",
    "    median_dict[r] = medians\n",
    "    left = percentile(2.5, medians)\n",
    "    right = percentile(97.5, medians)\n",
    "    CI = make_array(left, right)\n",
    "    print(\"The median 95% Confidence Interval for \" + r + \" is\", CI)\n",
    "    plt.plot(CI, make_array(i, i), lw=10, label=r)\n",
    "plt.legend(bbox_to_anchor=(1.01, 1), loc='upper left', ncol=1)\n",
    "plt.title('Bootstrap Median Income Confidence Intervals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do a one way F test to see if there is significance in the difference between the median samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats.f_oneway(median_dict['NA'], median_dict['Other'], median_dict['Indigenous'], median_dict['White'], median_dict['Black'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a fancy tool to give us all the combinations of `SEX` and `RACE` and then get the confidence intervals for those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "combos = [i for i in itertools.product(set(df['RACE']), ['MALE', 'FEMALE'])]\n",
    "combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, c in enumerate(combos):\n",
    "    subset = df[df['RACE'] == c[0]]\n",
    "    subset = Table.from_df(subset[subset['SEX'] == c[1]])\n",
    "    medians= bootstrap_median(subset, \"INCTOT\", 1000)\n",
    "    left = percentile(2.5, medians)\n",
    "    right = percentile(97.5, medians)\n",
    "    CI = make_array(left, right)\n",
    "    print(\"The median 95% Confidence Interval for \" + c[0] + ' ' + c[1] + \" is\", CI)\n",
    "    plt.plot(CI, make_array(i, i), lw=10, label=c[0] + ' ' + c[1])\n",
    "plt.legend(bbox_to_anchor=(1.01, 1), loc='upper left', ncol=1)\n",
    "plt.title('Bootstrap Median Income Confidence Intervals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "## Compared to entire Bay Area census sample\n",
    "\n",
    "So how does our tech-biased subset compare to the entire census subset of the Bay Area? First we'll do some quick processing to get out non-responses and relabel the Bay Area subset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bay_area = bay_area.to_df().replace({\"RACE\": race_dict, \"SEX\": {1: \"MALE\", 2: \"FEMALE\"}})\n",
    "bay_area = bay_area[bay_area[\"INCTOT\"] != 0]\n",
    "bay_area = bay_area[bay_area[\"INCTOT\"] != 99999999]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then look at income by `SEX` and `RACE`. Let's start with `SEX`.\n",
    "\n",
    "### `SEX`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bay_area.groupby(['SEX'])['INCTOT'].mean().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll recall that our biased subset had much higher means, but similar disparity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with_race.to_df().groupby(['SEX'])['INCTOT'].mean().plot.bar()n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UCB is doing much better than both of these subsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "professors.to_df().groupby(['Gender'])['Gross Pay'].mean().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `RACE`\n",
    "We can also look at `RACE` in the larger Bay Area subset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bay_area.groupby(['RACE'])['INCTOT'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bay_area.groupby(['RACE'])['INCTOT'].mean().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our biased subset was also great here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with_race.to_df().groupby(['RACE'])['INCTOT'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with_race.to_df().groupby(['RACE'])['INCTOT'].mean().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where are the disparities the worst? What does this tell us about the tech industry and management?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
